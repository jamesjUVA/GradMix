{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Functions and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "## Training Parameters\n",
    "numAugs = 0\n",
    "autoAugment = True\n",
    "bayesianRun = False\n",
    "testDataName='IEEEData'\n",
    "maxEpochs= 40\n",
    "train_split = 0\n",
    "## Base Parameters\n",
    "valPerc=.15\n",
    "learning_rate =.0001\n",
    "dim=224\n",
    "lr_step_size = 10\n",
    "batchsize=16\n",
    "dropout=False\n",
    "\n",
    "augRun=True\n",
    "if numAugs==0:\n",
    "    augRun=False\n",
    "print(augRun)\n",
    "\n",
    "## Import Torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision as torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir, islink,exists\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "import cv2\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "####\n",
    "\n",
    "mix_name='None'  ## Use mixup, None, or cutmix  all will use Class Sampling as Published\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need Pointer to Downloaded KCapsule Dataset\n",
    "# All images are downloaded unzipped in seperate folders by class\n",
    "KCapsule='/project/GutIntelligenceLab/jaj4zcf/Videos/KCapsule'\n",
    "\n",
    "split_0=pandas.read_csv(KCapsule+'/split_0.csv')\n",
    "split_1=pandas.read_csv(KCapsule+'/split_1.csv')\n",
    "KCclasses=[f for f in listdir(KCapsule) if '.' not in f]\n",
    "kvasir_paper=True\n",
    "if kvasir_paper==True:\n",
    "    class_dict={'Erosion':'ulcer', \n",
    "     'Lymphangiectasia':'mass',\n",
    "     'Blood - fresh':'bleeding',\n",
    "     'Erythema':'inflammation',\n",
    "     'Ulcer':'ulcer',\n",
    "     'Angiectasia':'angioectasia',\n",
    "     'Normal clean mucosa':'normal',\n",
    "     'Ileocecal valve': 'ileocecal valve',\n",
    "     'Pylorus': 'pylorus',\n",
    "     'Reduced mucosal view': 'reduced mucosal view',\n",
    "     'Foreign body':'foreign body'\n",
    "               }\n",
    "\n",
    "anatomy_list=[]\n",
    "datas=[]\n",
    "\n",
    "reclass=True \n",
    "for KCclass in KCclasses:\n",
    "    if reclass:\n",
    "        if KCclass not in class_dict:\n",
    "            continue\n",
    "    newData=pandas.DataFrame()\n",
    "    #print(KCclass)\n",
    "    classDir=KCapsule+'/'+KCclass\n",
    "    fileNames=listdir(classDir)\n",
    "    split0=[f in split_0['filename'].values for f in fileNames if '.jpg' in f]\n",
    "    newData['split0']=split0\n",
    "    files=[classDir + '/'+ f for f in fileNames if '.jpg' in f]\n",
    "    newData['files']=files\n",
    "    image_id=[KCclass + '/'+ f for f in fileNames if '.jpg' in f]\n",
    "    newData['image_id']=image_id\n",
    "    if reclass:\n",
    "        newData['pathology']=class_dict[KCclass]\n",
    "    else:\n",
    "        newData['pathology']=KCclass\n",
    "    datas.append(newData)\n",
    "    #print(KCclass)\n",
    "    #print(len(files))\n",
    "KCapsData=pandas.concat(datas, ignore_index=True)\n",
    "KCapsData.shape\n",
    "\n",
    "\n",
    "# Extract Just Ulcers for This Experiment\n",
    "\n",
    "labelsdf=KCapsData\n",
    "labelsdf=labelsdf[(labelsdf.pathology=='normal')|(labelsdf.pathology=='ulcer' )]\n",
    "print(np.sum(labelsdf.pathology=='ulcer'))\n",
    "print('ulcers')\n",
    "labelsdf\n",
    "\n",
    "## Data Statistics For Review\n",
    "pivot=pandas.pivot_table(KCapsData, values='files',index='split0',columns=['pathology'], aggfunc='count')\n",
    "\n",
    "\n",
    "# keeping only small bowel abnormalities represented in both classes\n",
    "pivot2=pivot.reset_index().melt(id_vars=['split0'])\n",
    "\n",
    "pivot2=pivot2.sort_values('value',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add An Index Per Class\n",
    "def finddr(x):\n",
    "    return np.where(x==np.sort(labelsdf.pathology.unique()))[0][0]\n",
    "labelsdf['dr']=labelsdf.pathology.apply(finddr)\n",
    "labelsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CutMix and Mixup Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, x2, y2, classes=2):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    \n",
    "    lam = np.random.beta(0.2, 1)\n",
    "        \n",
    "    mixed_x = lam * x + (1 - lam) * x2\n",
    "    y_out=np.zeros(classes)\n",
    "    y_out[y] = y_out[y] + lam\n",
    "    y_out[y2] = y_out[y2] + (1 - lam)\n",
    "    \n",
    "    return mixed_x, y_out\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    \n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix_data(x, y, x2, y2, alpha=1.0,classes=2):\n",
    "    # generate mixed sample\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.shape, lam)\n",
    "    x[bbx1:bbx2, bby1:bby2,:] = x2[bbx1:bbx2, bby1:bby2,:]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.shape[0] * x.shape[1]))\n",
    "    y_out=np.zeros(classes)\n",
    "    y_out[y] = y_out[y] + lam\n",
    "    y_out[y2] = y_out[y2] + (1 - lam)\n",
    "    # compute output\n",
    "    return x,y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset\n",
    "from PIL import Image\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, list_IDs, column='pathology', dims=(32,32,32), transform=False, mix='None'):\n",
    "        'Initialization'\n",
    "        self.dims = dims\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = self.list_IDs[column].unique().shape[0]\n",
    "        self.classes= np.array(sorted(self.list_IDs[column].unique()))\n",
    "        self.i = 0\n",
    "        self.column = column\n",
    "        self.transform = transform\n",
    "        self.mix = mix\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        ID = self.list_IDs.loc[index]\n",
    "        #print('here')\n",
    "        #print(ID)    \n",
    "        imCenterpath=ID['files']\n",
    "        img = Image.open(imCenterpath)\n",
    "        img = img.resize((self.dims[0],self.dims[1]))    \n",
    "        y = np.where(self.classes==ID[self.column])[0][0]\n",
    "        \n",
    "        if self.mix == 'None' or np.random.random()>.5:  #apply cutmix or mixup 50% of the time\n",
    "            y_out = np.zeros(self.n_classes)\n",
    "            y_out[y]=1\n",
    "        else:\n",
    "            ## Get Another Image to Blend\n",
    "            index1=np.random.randint(self.list_IDs.shape[0])\n",
    "            ID = self.list_IDs.loc[index1]\n",
    "            imCenterpath=ID['files']\n",
    "            img2 = Image.open(imCenterpath)\n",
    "            img2 = img2.resize((self.dims[0],self.dims[1]))\n",
    "            y2 = np.where(self.classes==ID[self.column])[0][0]\n",
    "            img = np.array(img)[:,:,:]\n",
    "            img2 = np.array(img2)[:,:,:]\n",
    "            if self.mix == 'cutmix':\n",
    "                img, y_out = cutmix_data(img, y, img2, y2)  \n",
    "            elif self.mix == 'mixup':\n",
    "                img, y_out = mixup_data(img, y, img2, y2)\n",
    "            img=Image.fromarray(img.astype('uint8'))\n",
    "        if self.transform:\n",
    "            #X = Image.fromarray(img)\n",
    "            X = self.transform(img)            \n",
    "            return X, y_out\n",
    "        else:\n",
    "            #X =  img /255\n",
    "            #X=np.rollaxis(X, 2, 0)  \n",
    "            return img, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split Training and Test by split0 and split1\n",
    "if train_split==0:\n",
    "    x_train=labelsdf[labelsdf.split0==False]\n",
    "    x_test=labelsdf[labelsdf.split0==True]\n",
    "else:\n",
    "    x_train=labelsdf[labelsdf.split0==True]\n",
    "    x_test=labelsdf[labelsdf.split0==False]\n",
    "    \n",
    "y_test=x_test\n",
    "print(x_train.pathology.unique())\n",
    "print(x_test.pathology.unique())\n",
    "#x_train, x_test, y_train, y_test = train_test_split(labelsdf, labelsdf, random_state=12, test_size=testPerc, shuffle=True,stratify=labelsdf['pathology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.to_csv('/project/DSone/jaj4zcf/Videos/models/'+testDataName+'.csv',index=False)\n",
    "#make valid for training\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, x_train,random_state=13, test_size=valPerc, shuffle= True,stratify=x_train['pathology'])\n",
    "abNormal=x_train[x_train['pathology']!='normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.reset_index(drop=True)\n",
    "y_val=y_val.reset_index(drop=True)\n",
    "y_test=y_test.reset_index(drop=True)\n",
    "x_train=x_train.reset_index(drop=True)\n",
    "x_val=x_val.reset_index(drop=True)\n",
    "x_test=x_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Mask Index\n",
    "Will be used later when doing gradient based image blend data augmnetation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['mask_index']=np.NaN\n",
    "i = 0\n",
    "for j in range(0,x_train.shape[0]):\n",
    "    if x_train.pathology.loc[j]=='ulcer':\n",
    "        x_train.mask_index.loc[j]=i\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Data Splits In Case Needed Later\n",
    "x_train.to_csv('train_VCE0.csv',index=False)\n",
    "x_test.to_csv('test_VCE0.csv',index=False)\n",
    "x_val.to_csv('val_VCE0.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used to Generate Grad-CAMs (run through trainin data without augmentation)\n",
    "x_train_no_reps=x_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Augmentation Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if autoAugment==True:\n",
    "     train_transform = transforms.Compose([\n",
    "            #transforms.Pad(padding=42),\n",
    "            transforms.RandomAffine(45, translate=(.2, .2), scale=(.8,1), shear=15),   \n",
    "            transforms.ColorJitter(brightness=(.9,1.1), contrast=(0.8, 1.2), saturation=(0.9, 1.1)), \n",
    "            #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.001, 5)),\n",
    "            \n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            #transforms.AutoAugment(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "else:\n",
    "    train_transform = transforms.Compose([\n",
    "            #transforms.Pad(padding=42),\n",
    "            #transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "#Training and Validation With Oversampling\n",
    "traingen=Dataset(x_train, column='pathology', dims=(dim,dim,3), transform=train_transform,mix = mix_name)\n",
    "valgen=Dataset(y_val, column='pathology', dims=(dim,dim,3), transform=val_transform)\n",
    "\n",
    "#Used to Create GRADCAMS\n",
    "traingen2=Dataset(x_train, column='pathology', dims=(dim,dim,3), transform=val_transform)\n",
    "\n",
    "#Test Dataset\n",
    "testgen=Dataset(y_test, column='pathology', dims=(dim,dim,3), transform=val_transform)\n",
    "\n",
    "#Test DataSet For Use With Test Time Augmentation\n",
    "testgenAug=Dataset(y_test, column='pathology', dims=(dim,dim,3), transform=train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Class Based Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': batchsize,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 1}\n",
    "\n",
    "traingenerator=torch.utils.data.DataLoader(traingen, **params)\n",
    "valgenerator=torch.utils.data.DataLoader(valgen, **params)\n",
    "\n",
    "testgenerator=torch.utils.data.DataLoader(testgen, **params)\n",
    "\n",
    "## Code adopted from Balanced Mixup\n",
    "## https://github.com/agaldran/balanced_mixup/\n",
    "def get_sampling_probabilities(class_count, mode='instance', ep=None, n_eps=None):\n",
    "    '''\n",
    "    Note that for progressive sampling I use n_eps-1, which I find more intuitive.\n",
    "    If you are training for 10 epochs, you pass n_eps=10 to this function. Then, inside\n",
    "    the training loop you would have sth like 'for ep in range(n_eps)', so ep=0,...,9,\n",
    "    and all fits together.\n",
    "    '''\n",
    "    if mode == 'instance':\n",
    "        q = 0\n",
    "    elif mode == 'class':\n",
    "        q = 1\n",
    "    elif mode == 'sqrt':\n",
    "        q = 0.5 # 1/2\n",
    "    elif mode == 'cbrt':\n",
    "        q = 0.125 # 1/8\n",
    "    elif mode == 'prog':\n",
    "        assert ep != None and n_eps != None, 'progressive sampling requires to pass values for ep and n_eps'\n",
    "        relative_freq_imbal = class_count ** 0 / (class_count ** 0).sum()\n",
    "        relative_freq_bal = class_count ** 1 / (class_count ** 1).sum()\n",
    "        sampling_probabilities_imbal = relative_freq_imbal ** (-1)\n",
    "        sampling_probabilities_bal = relative_freq_bal ** (-1)\n",
    "        return (1 - ep / (n_eps - 1)) * sampling_probabilities_imbal + (ep / (n_eps - 1)) * sampling_probabilities_bal\n",
    "    else: sys.exit('not a valid mode')\n",
    "\n",
    "    relative_freq = class_count ** q / (class_count ** q).sum()\n",
    "    sampling_probabilities = relative_freq ** (-1)\n",
    "\n",
    "    return sampling_probabilities\n",
    "\n",
    "def returnsampler(classcol, mode, ep=None, n_eps=None):\n",
    "    def retclass(x):\n",
    "        return np.where(classes==x)[0][0]\n",
    "    classes, class_count = np.unique(classcol, return_counts=True)\n",
    "    print(class_count)\n",
    "    sampling_probs = get_sampling_probabilities(class_count, mode=mode, ep=ep, n_eps=n_eps)\n",
    "    print(sampling_probs)\n",
    "    sample_weights = sampling_probs[classcol.apply(retclass)]\n",
    "    \n",
    "    mod_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights))\n",
    "    return mod_sampler\n",
    "mod_sampler=returnsampler(traingen.list_IDs.pathology, mode='class')\n",
    "\n",
    "params = {'batch_size': batchsize,\n",
    "          'num_workers': 4,\n",
    "         'sampler':mod_sampler}\n",
    "\n",
    "modtraingenerator=torch.utils.data.DataLoader(traingen, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Transform to False if You Want To See A Prview of Augmentations\n",
    "#traingen.transform=False\n",
    "img, y=traingen[12502]\n",
    "print(y)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = y_train.shape[0] / batchsize\n",
    "\n",
    "MEAN = torch.tensor([0.485, 0.456, 0.406])\n",
    "STD = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def train_model(model, traingenerator, valgenerator, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    training_loss=[]\n",
    "    val_loss=[]\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 100000\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                data=traingenerator\n",
    "            else:\n",
    "                data=valgenerator\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            \n",
    "            for inputs, labels in data:\n",
    "                inputs = inputs.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    #print(outputs)\n",
    "                    #print(labels)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #print(torch.max(labels,1))\n",
    "                running_corrects += torch.sum(preds == torch.max(labels, 1)[1])\n",
    "\n",
    "            \n",
    "            epoch_loss = running_loss / data.dataset.list_IDs.shape[0]\n",
    "            epoch_acc = running_corrects.double() / data.dataset.list_IDs.shape[0]\n",
    "            if phase == 'train':\n",
    "                training_loss.append(epoch_loss)\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                val_loss.append(epoch_loss)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_acc = epoch_acc\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                #torch.save(model_ft.state_dict(),'/project/DSone/jaj4zcf/Videos/models/thirdsmidTrainBlendSplit'+str(train_split))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, training_loss, val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #model_ft = models.resnet152(pretrained=True)\n",
    "    model_ft = models.resnet18(pretrained=False)\n",
    "\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    # Here the size of each output sample is set to 2.\n",
    "    # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "\n",
    "\n",
    "    if dropout==True:\n",
    "        print('Dropout')\n",
    "        model_ft.fc = nn.Sequential(nn.Dropout(0.5),nn.Linear(num_ftrs, 200),nn.ReLU(),nn.Dropout(0.5),nn.Linear(200, traingen.n_classes) )\n",
    "    else:\n",
    "        model_ft.fc = nn.Linear(num_ftrs, traingen.n_classes)\n",
    "\n",
    "\n",
    "    model_ft.to(device)\n",
    "    return model_ft, device\n",
    "model_ft, device=get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "You must set a location accessible for your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# In[ ]:\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
    "\n",
    "# Decay LR\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=lr_step_size, gamma=0.1)\n",
    "\n",
    "## Need to set a Location for Your Model \n",
    "model_loc='/project/DSone/jaj4zcf/Videos/models/ResNet_'+mix_name+'_Base_Train_on_Split'+str(train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft, training_loss, val_loss = train_model(model_ft, modtraingenerator, valgenerator, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=maxEpochs)\n",
    "torch.save(model_ft.state_dict(),model_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Prior to GradMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    model_ft.cuda()\n",
    "    \n",
    "def test_model(model, data):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    origLabels=np.array([])\n",
    "    predictions=np.array([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(data):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labelsOut = torch.max(labels,1)\n",
    "            predictions=np.append(predictions,np.array(preds.cpu()),axis=0)\n",
    "            origLabels=np.append(origLabels,np.array(labelsOut.cpu()),axis=0)\n",
    "            if i==0:\n",
    "                outputs_full=np.array(outputs.cpu())\n",
    "            else:\n",
    "                outputs_full=np.append(outputs_full,np.array(outputs.cpu()),axis=0)\n",
    "    model.train(mode=was_training)\n",
    "    return origLabels, predictions, outputs_full\n",
    "\n",
    "\n",
    "test_params = {'batch_size': 1,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelLoc='/project/DSone/jaj4zcf/Videos/models/ResNet_GradMix_Base_Train_on_Split'+str(train_split)\n",
    "model_ft, device_2=get_model()\n",
    "\n",
    "testgenerator=torch.utils.data.DataLoader(testgen, **test_params)\n",
    "model_ft.load_state_dict(torch.load(model_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loaded')\n",
    "labels, preds,outputs_full=test_model(model_ft, testgenerator)\n",
    "y_test['labels']=labels\n",
    "\n",
    "y_test['preds_']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.pathology.unique()\n",
    "mix_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massout=y_test[(y_test.pathology=='normal')]\n",
    "TN = np.sum(massout['preds_']==massout['labels'])\n",
    "FP = np.sum(massout['preds_']!=massout['labels'])\n",
    "\n",
    "\n",
    "massout=y_test[(y_test.pathology=='ulcer')]\n",
    "\n",
    "TP = np.sum(massout['preds_']!=0)\n",
    "FN = np.sum(massout['preds_']==0)\n",
    "\n",
    "## Overall Specificity\n",
    "print('accuracy')\n",
    "print(np.sum(y_test['preds_']==y_test['labels'])/y_test.shape[0])\n",
    "# True Postivies\n",
    "print('sensitivity')\n",
    "print(TP/(TP+FN))\n",
    "print('specificity')\n",
    "print(TN/(TN+FP))\n",
    "\n",
    "\n",
    "labels_base=labels\n",
    "preds_base=preds\n",
    "outputs_ful_base=outputs_full\n",
    "probs=[]\n",
    "for l in range(0,len(outputs_full)):\n",
    "    probs.append(np.exp(outputs_full[l])/np.sum(np.exp(outputs_full[l])))\n",
    "probs_base=probs\n",
    "print(accuracy_score(y_test['labels'],y_test['preds_']))\n",
    "print(precision_score(y_test['labels'],y_test['preds_']))\n",
    "print(recall_score(y_test['labels'],y_test['preds_']))\n",
    "print(f1_score(y_test['labels'],y_test['preds_']))\n",
    "roc_auc_score(labels,np.array(probs_base)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to Augment with Blended Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class BlendDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, list_IDs, test_column='pathology', masks=[], mask_classes=[], dims=(32,32,32), transform=False):\n",
    "        'Initialization'\n",
    "        self.dims = dims\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = self.list_IDs[test_column].unique().shape[0]\n",
    "        self.classes= np.array(sorted(self.list_IDs[test_column].unique()))\n",
    "        self.i = 0    \n",
    "        self.transform = transform\n",
    "        self.masks=masks\n",
    "        self.mask_classes=mask_classes\n",
    "        self.test_column = test_column\n",
    "        print(self.mask_classes)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def get_blend(self, ulcer_forground,masks,mask_num, lam = 1):\n",
    "        #print('blended')\n",
    "        \n",
    "        mask=masks[mask_num]\n",
    "        index1=np.random.randint(self.list_IDs.shape[0])\n",
    "        ID = self.list_IDs.loc[index1]\n",
    "        imCenterpath=ID['files']\n",
    "        #print(imCenterpath)\n",
    "        norm_background = Image.open(imCenterpath)\n",
    "        #print(ID)\n",
    "        y2 = np.where(self.classes==ID[self.test_column])[0][0]    \n",
    "        out_img = (mask[...,None] * np.array(ulcer_forground)[:,:,:]) + ((1-mask[...,None]) * np.array(norm_background)[:,:,:])\n",
    "        out_img=Image.fromarray(out_img.astype('uint8'))\n",
    "        y_out=np.zeros(self.n_classes)\n",
    "        y_out[1] = lam  #make 75% chance if it is abnormal\n",
    "        y_out[y2] = y_out[y2] + (1-lam)  # + 25% to either class depending on background\n",
    "        return out_img, y_out   \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        ID = self.list_IDs.loc[index]\n",
    "        #print('here')\n",
    "        #print(ID)    \n",
    "        imCenterpath=ID['files']\n",
    "        img = Image.open(imCenterpath)\n",
    "        y = np.where(self.classes==ID[self.test_column])[0][0]  \n",
    "        y_out = np.zeros(self.n_classes)\n",
    "        y_out[y]=1\n",
    "        if not np.isnan(x_train.loc[index].mask_index):\n",
    "            if np.random.random()>.5: # augment 50% of images\n",
    "                mask_class=x_train.loc[index].pathology\n",
    "                class_num=np.where(np.array(self.mask_classes)==mask_class)[0][0]\n",
    "                img, y_out = self.get_blend(img,self.masks[class_num],int(x_train.loc[index].mask_index))\n",
    "        \n",
    "        img = img.resize((self.dims[0],self.dims[1]))    \n",
    "\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            #X = Image.fromarray(img)\n",
    "            \n",
    "            X = self.transform(img)            \n",
    "            return X, y_out\n",
    "        else:\n",
    "            #X =  img /255\n",
    "            #X=np.rollaxis(X, 2, 0)  \n",
    "            return img, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GradCAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ulcers_val=np.where(x_train_no_reps.pathology=='ulcer')[0]\n",
    "import time\n",
    "cam = GradCAMPlusPlus(model=model_ft, target_layer=model_ft.layer4[-1], use_cuda=True)\n",
    "\n",
    "ulcer_cams=[]\n",
    "num_cams = len(np.where(x_train_no_reps.pathology=='ulcer')[0])\n",
    "i=0\n",
    "for ulcer in np.where(x_train_no_reps.pathology=='ulcer')[0]:\n",
    "    i=i+1\n",
    "    img, _ =traingen2[ulcer]\n",
    "    grayscale_cam=cam(img[None,:,:,:],target_category= [1] ,aug_smooth=True)\n",
    "    ulcer_cams.append(cv2.resize(grayscale_cam[0, :],(336,336)))\n",
    "    if i % 50 == 0:\n",
    "        print(i/num_cams)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Blending Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BlendTrain=BlendDataset(x_train, test_column='pathology',masks=[ulcer_cams], mask_classes=['ulcer'], dims=(dim,dim,3), transform=train_transform)  \n",
    "traingenerator=torch.utils.data.DataLoader(BlendTrain, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft, device_2=get_model()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# In[ ]:\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
    "\n",
    "# Decay LR\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=lr_step_size, gamma=0.1)\n",
    "\n",
    "# In[ ]:\n",
    "model_ft, training_loss, val_loss = train_model(model_ft, traingenerator, valgenerator, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=maxEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLoc='/project/DSone/jaj4zcf/Videos/models/ResNet_GradMix_Blended_mixup_Train_on_SplitLAM'+str(train_split)\n",
    "torch.save(model_ft.state_dict(),modelLoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft, device_2=get_model()\n",
    "model_ft.load_state_dict(torch.load(modelLoc))\n",
    "print('Loaded')\n",
    "testgenerator=torch.utils.data.DataLoader(testgen, **test_params)\n",
    "labels, preds,outputs_full=test_model(model_ft, testgenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['labels']=labels\n",
    "y_test['preds_']=preds\n",
    "massout=y_test[(y_test.pathology=='normal')]\n",
    "TN = np.sum(massout['preds_']==massout['labels'])\n",
    "FP = np.sum(massout['preds_']!=massout['labels'])\n",
    "\n",
    "massout=y_test[(y_test.pathology=='ulcer')]\n",
    "\n",
    "TP = np.sum(massout['preds_']!=0)\n",
    "FN = np.sum(massout['preds_']==0)\n",
    "\n",
    "## Overall Specificity\n",
    "print('accuracy')\n",
    "print(np.sum(y_test['preds_']==y_test['labels'])/y_test.shape[0])\n",
    "# True Postivies\n",
    "print('sensitivity')\n",
    "print(TP/(TP+FN))\n",
    "print('specificity')\n",
    "print(TN/(TN+FP))\n",
    "# for SB abnormal Class\n",
    "probs=[]\n",
    "for l in range(0,len(outputs_full)):\n",
    "    probs.append(np.exp(outputs_full[l])/np.sum(np.exp(outputs_full[l])))\n",
    "\n",
    "print(accuracy_score(y_test['labels'],y_test['preds_']))\n",
    "print(precision_score(y_test['labels'],y_test['preds_']))\n",
    "print(recall_score(y_test['labels'],y_test['preds_']))\n",
    "print(f1_score(y_test['labels'],y_test['preds_']))\n",
    "roc_auc_score(labels,np.array(probs)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class_num=0\n",
    "\n",
    "ulc_fpr, ulc_tpr, _=roc_curve(labels, np.array(probs)[:,class_num])\n",
    "    \n",
    "ulc_fprB, ulc_tprB, _=roc_curve(labels, np.array(probs_base)[:,class_num]) \n",
    "\n",
    "from matplotlib import pyplot\n",
    "# plot the roc curve for the model\n",
    "fig = pyplot.figure(figsize=(4, 4))\n",
    "pyplot.plot(ulc_fprB, ulc_tprB, linestyle='--', label='Base')\n",
    "pyplot.plot(ulc_fpr, ulc_tpr, linestyle='-.', label='GradMix')\n",
    "\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "\n",
    "pyplot.legend(loc='lower right')\n",
    "# show the plot\n",
    "#pyplot.tight_layout()\n",
    "pyplot.axis('equal')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.10.0",
   "language": "python",
   "name": "pytorch-1.10.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
